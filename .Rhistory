res = tuneParams(learner = lrn,
task = task,
resampling = rdesc,
par.set = ps,
control = ctrl,
show.info =FALSE)
psdata = generateHyperParsEffectData(res)
plotHyperParsEffect(psdata, x = "iteration", y  ="mmce.test.mean", plot.type ="line")
psdata
psdata$data
plot(psdata$data$cp, psdata$data$mmce.test.mean)
plot(psdata$data$[,1], psdata$data$mmce.test.mean)
plot(psdata$data[,1], psdata$data$mmce.test.mean)
psdata = generateHyperParsEffectData(res)
plot(psdata$data[,1], psdata$data$mmce.test.mean), x = "parameter_value", y  ="mmce.test.mean")
psdata = generateHyperParsEffectData(res)
plot(psdata$data[,1], psdata$data$mmce.test.mean, x = "parameter_value", y  ="mmce.test.mean")
?plot
psdata = generateHyperParsEffectData(res)
plot(psdata$data[,1], psdata$data$mmce.test.mean,
xlab = "parameter_value", ylab  ="mmce.test.mean")
psdata = generateHyperParsEffectData(res)
plotHyperParsEffect(psdata, x = "iteration", y = "mmce.test.mean", plot.type = "line")
plot(psdata$data[,1], psdata$data$mmce.test.mean,
xlab = "parameter_value", ylab  ="mmce.test.mean")
tuned_lrn = setHyperPars(lrn, par.vals = res$x)
m = train(learner = tuned_lrn, task = task)
task_test = makeClassifTask(data = data_dummified[data_split$test.inds[[1]],  ], target = 'churn')
pred_test = predict(m, task = task_test)
pred_test
r
calculateConfusionMatrix(pred_test)
predList$test$`1`
calculateConfusionMatrix(pred_test)
m = train(learner = tuned_lrn, task = task)
task_test = makeClassifTask(data = data_dummified[data_split$test.inds[[1]],  ], target = 'churn')
pred_test = predict(object = m, task = task_test)
calculateConfusionMatrix(pred_test)
rm(tree_mod,test_task,pred_on_test,d)
m = train(learner = tuned_lrn, task = task)
task_test = makeClassifTask(data = data_dummified[data_split$test.inds[[1]],  ], target = 'churn')
pred_on_test = predict(object = m, task = task_test)
calculateConfusionMatrix(pred_on_test)
d = generateThreshVsPerfData(pred_on_test, measures = list(fpr, tpr))
plotROCCurves(d)
#generateThreshVsPerfData(list(rpart  =pred1,kknn  =pred2),measures  =list(fpr,  tpr))
performance(pred_on_test, measures = auc)
library(ggplot2)
rv <- sort(rexp(1000))
qplot(rv)
qplot(rv)
?pexp
library(caret)
rv <- rexp(1000, rate = 1)
qplot(rv)
?rexp
rv.bc <- BoxCoxTrans(rv)
??BoxCoxTrans
library(caret)
install.packages("caret")
library(caret)
rm(caret)
install.packages("prodlim")
library(caret)
library(prodlim)
library(caret)
library(caret)
install.packages("caret")
library(caret)
install.packages("purrr")
library(caret)
rv <- rexp(1000, rate = 1)
rv.bc <- BoxCoxTrans(rv)
rv.bc
3^3
3**3
plot(rv^bc.lambda)
bc.lambda <- rv.bc$lambda
plot(rv^bc.lambda)
hist(rv^bc.lambda)
rv.transformed <- (rv^bc.lambda - 1) / bc.lambda
hist(rv.transformed)
library(mlr)
library(ggplot2)
library(robustHD)
library(readr)
data <- read_csv("E:/bitbucket_warehouse/side_projects/phone_churn/dataset/ACMETelephoneABT.csv")
table(data$churn)
sapply(data, function(x) sum(is.na(x)))
data$occupation[is.na(data$occupation)] = 'missing'
data_no_handling = data
data_no_handling$regionType[is.na(data_no_handling$regionType)] = 'missing'
data$customer = NULL
table(data$regionType)
data$regionType[data$regionType == 'r'] = 'rural'
data$regionType[data$regionType == 's'] = 'suburban'
data$regionType[data$regionType == 't'] = 'town'
data$regionType[data$regionType == 'unknown'] = NA
table(data$creditCard)
data$creditCard[data$creditCard == 'f'] = 'false'
data$creditCard[data$creditCard == 'no'] = 'false'
data$creditCard[data$creditCard == 't'] = 'true'
data$creditCard[data$creditCard == 'yes'] = 'true'
table(data$numHandsets)
table(data$currentHandsetPrice)
hist(data$age)
data$age[data$age == 0] = NA
data = as.data.frame(unclass(data), stringsAsFactors=TRUE)
imp = impute(data,
target = "churn", # Tell the algorithm not to use information in the target column for imputation.
cols = list(
regionType = imputeLearner("classif.cforest"),
age = imputeLearner("regr.cforest")
)
)
table(imp$data$regionType)
hist(imp$data$age)
data_imputed = imp$data
data_imputed$regionType = data$regionType
levels(data_imputed$regionType) = c(levels(data_imputed$regionType), 'missing')
data_imputed$regionType[is.na(data_imputed$regionType)] = 'missing'
library(caret)
hist(data_imputed$currentHandsetPrice)
test = BoxCoxTrans(data_imputed$currentHandsetPrice)
test$summary
test
test$n
BoxCoxTransformation = function(original_data) {
lambda = BoxCoxTrans(original_data)$lambda
return((original_data ** lambda - 1)/ lambda)
}
hist(data_imputed$currentHandsetPrice)
hist(data_imputed$currentHandsetPrice, breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice), breaks = 20)
BoxCoxTransformation(data_imputed$currentHandsetPrice)
BoxCoxTrans(data_imputed$currentHandsetPrice)
BoxCoxTrans(data_imputed$currentHandsetPrice + 1)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 10), breaks = 20)
hist(data_imputed$currentHandsetPrice + 10)
hist(data_imputed$currentHandsetPrice + 10, breaks = 20)
summary(data_imputed$currentHandsetPrice + 10)
test = data_imputed$currentHandsetPrice + 10
hist(test)
hist(test, breaks = 10)
hist(test, breaks = 20)
hist(test, breaks = 100)
hist(BoxCoxTransformation(test), breaks = 20)
pexp(data_imputed$currentHandsetPrice)
qnorm(pexp(data_imputed$currentHandsetPrice))
qnorm(pexp(data_imputed$currentHandsetPrice+1))
qnorm(pexp(data_imputed$currentHandsetPrice+100))
qnorm(pexp(data_imputed$currentHandsetPrice+1))
hist(data_imputed$numHandsets, breaks = 30)
hist(data_imputed$avgOverBundleMins, breaks = 30)
hist(data_imputed$avgRoamCalls, breaks = 30)
hist(data_imputed$avgReceivedMins, breaks = 30)
hist(BoxCoxTransformation(data_imputed$avgReceivedMins + 10), breaks = 20)
hist(BoxCoxTransformation(data_imputed$avgReceivedMins + 1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$avgReceivedMins), breaks = 20)
hist(BoxCoxTransformation(data_imputed$avgReceivedMins+1), breaks = 20)
hist(log(data_imputed$avgReceivedMins+1), breaks = 20)
hist(log(data_imputed$avgReceivedMins), breaks = 20)
log(data_imputed$avgReceivedMins)
log(data_imputed$avgReceivedMins+1)
hist(log(data_imputed$avgReceivedMins + 1), breaks = 20)
hist(data_imputed$avgOutCalls, breaks = 20)
hist(data_imputed$avgInCalls, breaks = 20)
hist(data_imputed$peakOffPeakRatio, breaks = 20)
hist(data_imputed$avgDroppedCalls, breaks = 20)
hist(data_imputed$lastMonthCustomerCareCalls, breaks = 20)
hist(data_imputed$numRetentionCalls, breaks = 20)
hist(data_imputed$numRetentionOffersAccepted, breaks = 20)
hist(data_imputed$newFrequentNumbers, breaks = 20)
rv <- rexp(1000, rate = 1)
qplot(rv)
summary(rv)
hist(BoxCoxTransformation(data_imputed$avgReceivedMins + 1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$avgReceivedMins + 1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$newFrequentNumbers + 1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 1), breaks = 20)
hist(log(data_imputed$newFrequentNumbers + 1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 10000), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 10), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 100), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 1000), breaks = 20)
?BoxCoxTrans
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 0.1), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 0.00001), breaks = 20)
hist(BoxCoxTransformation(rexp(1000)), breaks = 20)
hist(rexp(1000))
summary(rexp(1000))
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 0.01), breaks = 20)
hist(BoxCoxTransformation(data_imputed$currentHandsetPrice + 0.01), breaks = 20)
BoxCoxTransformation(data_imputed$currentHandsetPrice)
BoxCoxTransformation(data_imputed$currentHandsetPrice+0.0001)
?BoxCoxTrans
hist(data_imputed$numHandsets, breaks = 20)
hist(BoxCoxTransformation(data_imputed$numHandsets), breaks = 20)
summary(BoxCoxTransformation(data_imputed$numHandsets))
hist(qexp(pnorm(BoxCoxTransformation(data_imputed$numHandsets))))
hist(qexp(pnorm(data_imputed$numHandsets)))
?qgeom
hist(qgeom(pnorm(data_imputed$numHandsets)))
hist(qexp(pnorm(qnorm(data_imputed$numHandsets))))
hist(qexp(pnorm(qnorm(data_imputed$numHandsets+1))))
hist(qexp(pnorm(qnorm(data_imputed$numHandsets))))
hist(qexp(pnorm(qnorm(pexp(sort(rexp(1000)))))))
rv <- sort(rexp(1000))
qplot(rv)
cdfy <- pexp(rv)
invcdf <- qnorm(cdfy)
qplot(invcdf)
qplot(qexp(pnorm(qnorm(pexp(sort(rexp(1000)))))))
hist(invcdf)
hist(qnorm(pexp(sort(rexp(1000)))))
hist(qnorm(pexp(rexp(1000))))
hist(qnorm(pexp(sort(rexp(1000)))))
hist(qnorm(pexp(rexp(1000))))
hist(qnorm(pexp(data$numHandsets)))
hist(qnorm(pgoem(data$numHandsets)))
hist(qnorm(pgeom(data$numHandsets)))
?pgeom
?pexp
hist(qnorm(ppois(data$numHandsets)))
?ppois
hist(qnorm(ppois(data$numHandsets, lambda = 1)))
hist(qnorm(ppois(data$numHandsets, lambda = 0.1)))
hist(qnorm(ppois(data$numHandsets, lambda = 0.01)))
hist(qnorm(ppois(data$numHandsets, lambda = 0.0001)))
hist(qnorm(ppois(data$numHandsets, lambda = 0.5)))
hist(qnorm(ppois(data$numHandsets, lambda = 2)))
hist(qnorm(ppois(data$numHandsets, lambda = 3)))
hist(qnorm(ppois(data$numHandsets, lambda = 5)))
hist(qnorm(ppois(data$numHandsets, lambda = 10)))
rpois(lambda = 1)
hist(rpois(1000, lambda = 1))
hist(rpois(1000, lambda = 0.1))
hist(qnorm(ppois(data$numHandsets, lambda = 0.2)))
hist(qnorm(pexp(rexp(1000))))
hist(qnorm(ppois(data$numHandsets, lambda = 0.2)))
hist(qnorm(ppois(data$numHandsets, lambda = 1)))
hist(qnorm(ppois(data$numHandsets, lambda = 10)))
hist(qnorm(ppois(data$numHandsets, lambda = 100)))
hist(data$numHandsets)
hist(rpois(1000, lambda = 0.1))
hist(rpois(10000, lambda = 5))
hist(rpois(10000, lambda = 1))
hist(rpois(10000, lambda = 0.5))
hist(rpois(10000, lambda = 0.1))
hist(data$numHandsets)
hist(rexp(1000, rate = 0.1))
hist(rexp(10000, rate = 0.1))
hist(data$numHandsets)
hist(rexp(10000, rate = 0.01))
hist(rexp(10000, rate = 0.1))
hist(rexp(10000, rate = 1))
hist(data$numHandsets)
hist(rexp(10000, rate = 3))
hist(qnorm(pexp(rexp(10000, rate = 3))))
hist(rexp(10000, rate = 3))
hist(rexp(10000, rate = 5))
hist(rexp(10000, rate = 7))
hist(rexp(10000, rate = 5))
summary(rexp(10000, rate = 7))
hist(BoxCoxTransformation(data$numHandsets))
hist(BoxCoxTransformation(data$numHandsets - 1))
hist(BoxCoxTransformation(data$numHandsets))
hist(BoxCoxTransformation(data$numHandsets+5))
hist(data$numHandsets)
rm(bc.lambda,rv, rv.bc,rv.transformed)
rm(invcdf)
hist(data_imputed$numHandsets)
hist(data_imputed$numHandsets)
hist(BoxCoxTransformation(data_imputed$numHandsets))
summary(data_imputed$numHandsets)
data_imputed$numHandsets = BoxCoxTransformation(data_imputed$numHandsets)
data_imputed$currentHandsetPrice = BoxCoxTransformation(data_imputed$currentHandsetPrice + 1)
data_imputed$avgOverBundleMins = BoxCoxTransformation(data_imputed$avgOverBundleMins + 1)
data_imputed$avgRoamCalls = BoxCoxTransformation(data_imputed$avgRoamCalls + 1)
data_imputed$avgReceivedMins = BoxCoxTransformation(data_imputed$avgReceivedMins + 1)
data_imputed$avgOutCalls = BoxCoxTransformation(data_imputed$avgOutCalls + 1)
data_imputed$avgInCalls = BoxCoxTransformation(data_imputed$avgInCalls + 1)
data_imputed$peakOffPeakRatio = BoxCoxTransformation(data_imputed$peakOffPeakRatio + 1)
data_imputed$avgDroppedCalls = BoxCoxTransformation(data_imputed$avgDroppedCalls + 1)
data_imputed$lastMonthCustomerCareCalls = BoxCoxTransformation(data_imputed$lastMonthCustomerCareCalls + 1)
data_imputed$numRetentionCalls = BoxCoxTransformation(data_imputed$numRetentionCalls + 1)
data_imputed$numRetentionOffersAccepted = BoxCoxTransformation(data_imputed$numRetentionOffersAccepted + 1)
data_imputed$newFrequentNumbers = BoxCoxTransformation(data_imputed$newFrequentNumbers + 1)
numerical_col_index <- unlist(lapply(data_imputed, is.numeric))  # For all numerical columns
data_standardised = lapply(data_imputed[ , numerical_col_index], standardize) # Standardise it
mean(data_standardised$currentHandsetPrice)
sd(data_standardised$currentHandsetPrice)
categorical_col_index = !numerical_col_index
data_standardised = cbind(data_standardised, data_imputed[ , categorical_col_index])
data_dummified = createDummyFeatures(data_standardised, target = 'churn', method = "reference", cols = NULL)
?createDummyFeatures
set.seed(1234)
data_split = makeResampleInstance(desc = 'Holdout',
task = makeClassifTask(data = data_dummified,
target = 'churn'),
split = 0.8,
stratify = TRUE)
data_imputed$avgDroppedCalls
data_imputed = imp$data
data_imputed$regionType = data$regionType
levels(data_imputed$regionType) = c(levels(data_imputed$regionType), 'missing')
data_imputed$regionType[is.na(data_imputed$regionType)] = 'missing'
hist(data_imputed$avgDroppedCalls)
summary(data_imputed$avgDroppedCalls)
summary(BoxCoxTransformation(data_imputed$avgDroppedCalls + 1))
BoxCoxTrans(data_imputed$avgDroppedCalls + 1)$lambda
BoxCoxTransformation = function(original_data) {
lambda = BoxCoxTrans(original_data)$lambda
if (lambda == 0) {
return(log(original_data))
} else {
return((original_data ** lambda - 1)/ lambda)
}
}
data_imputed$numHandsets = BoxCoxTransformation(data_imputed$numHandsets)
data_imputed$currentHandsetPrice = BoxCoxTransformation(data_imputed$currentHandsetPrice + 1)
data_imputed$avgOverBundleMins = BoxCoxTransformation(data_imputed$avgOverBundleMins + 1)
data_imputed$avgRoamCalls = BoxCoxTransformation(data_imputed$avgRoamCalls + 1)
data_imputed$avgReceivedMins = BoxCoxTransformation(data_imputed$avgReceivedMins + 1)
data_imputed$avgOutCalls = BoxCoxTransformation(data_imputed$avgOutCalls + 1)
data_imputed$avgInCalls = BoxCoxTransformation(data_imputed$avgInCalls + 1)
data_imputed$peakOffPeakRatio = BoxCoxTransformation(data_imputed$peakOffPeakRatio + 1)
data_imputed$avgDroppedCalls = BoxCoxTransformation(data_imputed$avgDroppedCalls + 1)
data_imputed$lastMonthCustomerCareCalls = BoxCoxTransformation(data_imputed$lastMonthCustomerCareCalls + 1)
data_imputed$numRetentionCalls = BoxCoxTransformation(data_imputed$numRetentionCalls + 1)
data_imputed$numRetentionOffersAccepted = BoxCoxTransformation(data_imputed$numRetentionOffersAccepted + 1)
data_imputed$newFrequentNumbers = BoxCoxTransformation(data_imputed$newFrequentNumbers + 1)
numerical_col_index <- unlist(lapply(data_imputed, is.numeric))  # For all numerical columns
data_standardised = lapply(data_imputed[ , numerical_col_index], standardize) # Standardise it
mean(data_standardised$currentHandsetPrice)
sd(data_standardised$currentHandsetPrice)
categorical_col_index = !numerical_col_index
data_standardised = cbind(data_standardised, data_imputed[ , categorical_col_index])
data_dummified = createDummyFeatures(data_standardised, target = 'churn', method = "reference", cols = NULL)
set.seed(1234)
data_split = makeResampleInstance(desc = 'Holdout',
task = makeClassifTask(data = data_dummified,
target = 'churn'),
split = 0.8,
stratify = TRUE)
?rpart
set.seed(1234)
data_split = makeResampleInstance(desc = 'Holdout',
task = makeClassifTask(data = data_dummified,
target = 'churn'),
split = 0.8,
stratify = TRUE)
rdesc = makeResampleDesc("CV", iters = 5, stratify = TRUE)
task = makeClassifTask(data = data_dummified[data_split$train.inds[[1]],  ], target = 'churn')
lrn = makeLearner(cl = "classif.rpart", predict.type ='prob')
ps = makeParamSet(makeNumericParam('cp', lower = 0.002, upper = 0.1),
makeNumericParam('maxdepth', lower = 2, upper = 30))
ctrl = makeTuneControlRandom(maxit = 30L)
res = tuneParams(learner = lrn,
task = task,
resampling = rdesc,
par.set = ps,
control = ctrl,
show.info =FALSE)
psdata = generateHyperParsEffectData(res)
plotHyperParsEffect(psdata, x = "iteration", y = "mmce.test.mean", plot.type = "line")
?makeDiscreteParam
rdesc = makeResampleDesc("CV", iters = 5, stratify = TRUE)
task = makeClassifTask(data = data_dummified[data_split$train.inds[[1]],  ], target = 'churn')
lrn = makeLearner(cl = "classif.rpart", predict.type ='prob')
ps = makeParamSet(makeNumericParam('cp', lower = 0.002, upper = 0.1),
makeIntegerParam('maxdepth', lower = 2, upper = 30))
ctrl = makeTuneControlRandom(maxit = 30L)
res = tuneParams(learner = lrn,
task = task,
resampling = rdesc,
par.set = ps,
control = ctrl,
show.info =FALSE)
psdata = generateHyperParsEffectData(res)
plotHyperParsEffect(psdata, x = "iteration", y = "mmce.test.mean", plot.type = "line")
res$control
res$y
res$opt.path
psdata$data
rdesc = makeResampleDesc("CV", iters = 5, stratify = TRUE)
task = makeClassifTask(data = data_dummified[data_split$train.inds[[1]],  ], target = 'churn')
lrn = makeLearner(cl = "classif.rpart", predict.type ='prob')
ps = makeParamSet(makeNumericParam('cp', lower = 0.002, upper = 0.03),
makeIntegerParam('maxdepth', lower = 2, upper = 30))
ctrl = makeTuneControlRandom(maxit = 30L)
res = tuneParams(learner = lrn,
task = task,
resampling = rdesc,
par.set = ps,
control = ctrl,
show.info =FALSE)
psdata = generateHyperParsEffectData(res)
plotHyperParsEffect(psdata, x = "iteration", y = "mmce.test.mean", plot.type = "line")
rdesc = makeResampleDesc("CV", iters = 5, stratify = TRUE)
task = makeClassifTask(data = data_dummified[data_split$train.inds[[1]],  ], target = 'churn')
lrn = makeLearner(cl = "classif.rpart", predict.type ='prob')
ps = makeParamSet(makeNumericParam('cp', lower = 0.001, upper = 0.03),
makeIntegerParam('maxdepth', lower = 2, upper = 30))
ctrl = makeTuneControlRandom(maxit = 40L)
res = tuneParams(learner = lrn,
task = task,
resampling = rdesc,
par.set = ps,
control = ctrl,
show.info =FALSE)
set.seed(1234)
data_split = makeResampleInstance(desc = 'Holdout',
task = makeClassifTask(data = data_dummified,
target = 'churn'),
split = 0.7,
stratify = TRUE)
rdesc = makeResampleDesc("CV", iters = 5, stratify = TRUE)
task = makeClassifTask(data = data_dummified[data_split$train.inds[[1]],  ], target = 'churn')
lrn = makeLearner(cl = "classif.rpart", predict.type ='prob')
ps = makeParamSet(makeNumericParam('cp', lower = 0.001, upper = 0.03),
makeIntegerParam('maxdepth', lower = 2, upper = 30))
ctrl = makeTuneControlRandom(maxit = 40L)
res = tuneParams(learner = lrn,
task = task,
resampling = rdesc,
par.set = ps,
control = ctrl,
show.info =FALSE)
psdata = generateHyperParsEffectData(res)
plotHyperParsEffect(psdata, x = "iteration", y = "mmce.test.mean", plot.type = "line")
lrn; tuned_lrn
tuned_lrn = setHyperPars(lrn, par.vals = res$x)
lrn; tuned_lrn
install.packages("spFSR")
library(spFSR)
install.packages("parallelMap")
library(jsonlite)
library(spFSR)
library(spFSR)
library(parallel)
library(spFSR)
library(parallel)
library(spFSR)
remove.packages("parallel", lib="C:/Program Files/R/R-3.4.0/library")
library(parallel)
library(spFSR)
detach("package:parallel", unload=TRUE)
detach("package:parallelMap", unload=TRUE)
library("parallelMap", lib.loc="~/R/win-library/3.4")
library("bindr", lib.loc="~/R/win-library/3.4")
detach("package:bindr", unload=TRUE)
library("parallel", lib.loc="C:/Program Files/R/R-3.4.0/library")
library(mlr)
library(ggplot2)
library(robustHD)
library(readr)
library(caret)
library(spFSR)
library(jsonlite)
remove.packages("parallel", lib="C:/Program Files/R/R-3.4.0/library")
remove.packages("parallel", lib="C:/Program Files/R/R-3.4.0/library")
setwd("E:/bitbucket_warehouse/side_projects/phone_churn")
res_tree
rm(task)
data_no_handling$occupation[is.na(data_no_handling$occupation)] = 'missing'
data_no_handling = as.data.frame(unclass(data_no_handling), stringsAsFactors=TRUE)
data_no_handling_dummified =
createDummyFeatures(data_no_handling, target = 'churn', method = "reference", cols = NULL)
library(mlr)
library(ggplot2)
library(robustHD)
library(readr)
library(caret)
library(spFSR)
library(jsonlite)
data_no_handling$occupation[is.na(data_no_handling$occupation)] = 'missing'
data_no_handling = as.data.frame(unclass(data_no_handling), stringsAsFactors=TRUE)
data_no_handling_dummified =
createDummyFeatures(data_no_handling, target = 'churn', method = "reference", cols = NULL)
data_no_handling_split_for_tree = makeResampleInstance(desc = 'Holdout',
task = makeClassifTask(data = data_no_handling_dummified,
target = 'churn'),
split = 0.7,
stratify = TRUE)
CV_and_train_data_tree = data_no_handling_dummified[data_no_handling_split_for_tree$train.inds[[1]], ]
test_data_tree = data_no_handling_dummified[data_no_handling_split_for_tree$test.inds[[1]], ]
rdesc = makeResampleDesc("CV", iters = 5, stratify = TRUE)
task = makeClassifTask(data = CV_and_train_data_tree,
target = 'churn')
lrn_tree = makeLearner(cl = "classif.rpart", predict.type ='prob')
ps_tree = makeParamSet(makeNumericParam('cp', lower = 0.001, upper = 0.03),
makeIntegerParam('maxdepth', lower = 2, upper = 30))
ctrl_tree = makeTuneControlRandom(maxit = 40L)
res_tree = tuneParams(learner = lrn_tree,
task = task,
resampling = rdesc,
par.set = ps_tree,
control = ctrl_tree,
show.info =FALSE)
lrn_tree_tuned = setHyperPars(lrn_tree, par.vals = res_tree$x)
spsaMod_tree_tuned = spFeatureSelection(task, wrapper = lrn_tree_tuned,
measure = auc, num.features.selected = 0)
task_test = makeClassifTask(data = test_data_tree, target = 'churn')
pred_on_test_spsa_tree_tuned = predict(object = spsaMod_tree_tuned$best.model, task = task_test)
performance(pred_on_test_spsa_tree_tuned, measures = auc)
View(data_no_handling_dummified)
data_no_handling_dummified
dim(data_no_handling_dummified)
str(data_no_handling_dummified)
